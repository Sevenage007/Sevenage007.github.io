<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>LDA主题模型第二步：文本情感分析</title>
      <link href="/posts/54205.html"/>
      <url>/posts/54205.html</url>
      
        <content type="html"><![CDATA[<h1 id="情感分析简介"><a href="#情感分析简介" class="headerlink" title="情感分析简介"></a>情感分析简介</h1><p>度过了愉快的五一假期,准备开工，今天主要介绍的是文本情感分析,简单来说，就是对带有情感色彩的主观性文本进行处理、分析、归纳和推理的过程。在互联网上，每天都产生了大量带有情感色彩的文本。例如微博，知乎中关于某一主题的讨论，亦或是淘宝，京东中对商品的评论。这些评论表达了人们的情感色彩和情感倾向。例如：喜、怒、哀、乐、支持、反对、中立等等。情感分析的主要目的是通过分析这些评论来了解某一群体对于某一话题或某一事情的态度和看法。</p><h1 id="在护理中的应用"><a href="#在护理中的应用" class="headerlink" title="在护理中的应用"></a>在护理中的应用</h1><p>事实上情感分析在护理领域仍处于起步阶段，但有很大的应用空间。</p><h2 id="一-患者对某一疾病的态度"><a href="#一-患者对某一疾病的态度" class="headerlink" title="(一)患者对某一疾病的态度"></a>(一)患者对某一疾病的态度</h2><p>通过分析在线健康信息平台中患者的提问，可以了解患者对该疾病的态度，并比较不同态度患者一般资料差异（也可以比较其他信息，但需要在网络中能提取出）；通过分析百度贴吧或天涯社区中帖子的具体内容，来分析患者对某一疾病的情感，是担忧、害怕还是积极乐观；</p><h2 id="二-情绪变化（纵向研究）"><a href="#二-情绪变化（纵向研究）" class="headerlink" title="(二)情绪变化（纵向研究）"></a>(二)情绪变化（纵向研究）</h2><p>通过分析微博树洞中用户发布的内容，了解该用户情绪变化，哪种情绪多一点，进而可以分析他的性格。此外，通过纵向追踪该用户发帖主题的变化，以及帖子的具体内容，凝练提取导致此类性格用户产生某一情绪改变的原因是什么。那么，我们了解这些情感信息可以做什么呢？事实上，现在不同年龄阶段中存在心理健康问题（例如抑郁、焦虑、压力）的人有很多，这些问题不是短时间形成的，往往是在长期的负性事件积累中产生。而许多人不愿意和他人或是父母倾诉，网络的匿名性使得这些人群更愿意通过匿名发帖来吐槽一些事情，或是倾诉某一情感。以青少年为例，如今青少年自杀率逐年升高，抑郁是其自杀的一个重要原因，而在抑郁产生之前，实际上有很多负性事件的积累，例如可能来自家庭的压力过大（家长期望值过高）、遭遇校园暴力和霸凌等等。青少年用户在社交媒体中占了主要部分，当一些情绪或遭遇的时间不愿意和家人或老师诉说时，社交媒体成为这类人群情绪的主要宣泄地。<font color=red> 因此，如果能够提前了解这类用户的情绪变化，构建基于文本情感分析模型的心理健康智能评测系统和心理危机预警系统，将干预提前，可以有效降低这类用户自伤率和自杀率。 </font>情感分析还有很多应用，不止于此，这里只是抛砖引玉。</p><h1 id="情感分析前期准备"><a href="#情感分析前期准备" class="headerlink" title="情感分析前期准备"></a>情感分析前期准备</h1><p>R语言和Python都可以进行情感分析，但作为机器学习中的方法之一，Python在情感分析方面比R更具优势，因此我们主要使用Python进行。</p><h2 id="一-安装最新版Python和PyCharm"><a href="#一-安装最新版Python和PyCharm" class="headerlink" title="(一)安装最新版Python和PyCharm"></a>(一)安装最新版Python和PyCharm</h2><p>这个安装过程可以看这篇文章，因为知乎上有现成的教程，也很详细，我就不自己出教程了，是用户:星际探险家写的，大家点击链接直达教程，大家一定要记得安装包安装的位置<a href="https://zhuanlan.zhihu.com/p/51780281"  target="_blank"> <font color=red > Python菜鸟入阶第一步（安装Python+PyCharm）</font> </a> <br></p><h2 id="二-新建项目"><a href="#二-新建项目" class="headerlink" title="(二)新建项目"></a>(二)新建项目</h2><p>打开pycharm，点击新建项目，项目位置自己设定，记住就行，我是放在D盘了，项目命名为Pythonworkplace。这个命名可以随意，自己能记住就行。如下图，新建后默认会出现一个示例代码，大家点击main.py，右键运行后，下方出现图二中的Hi, PyCharm 表示操作成功。然后大家就可以把这个示例代码删了。直接按Ctrl+A全选，然后删除。<br><img src="https://s2.loli.net/2023/05/02/H3eIbQWs7qxaOiL.png" alt="11.png"><br><img src="https://s2.loli.net/2023/05/02/iG6yAajVdzcvfNn.png" alt="22.png"></p><h2 id="三-安装软件包"><a href="#三-安装软件包" class="headerlink" title="(三)安装软件包"></a>(三)安装软件包</h2><p>首先请大家安装pandas包，、jieba包、wordcloud包、tqdm包和snownlp包。pandas包主要是用来读取和写入数据的，jieba包用来进行分词，去除停用词，wordcloud包用来绘制词云图，tqdm包主要是显示进度条用的，snownlp包最关键，主要用于情感分析。安装图例如下图，在软件底部点击“python packages”，搜索对应数据包后即可下载，下载稍慢，需要等一会。<br><img src="https://s2.loli.net/2023/05/02/NksIKDWf4MQoYBu.png" alt="44.png"><br><img src="https://s2.loli.net/2023/05/02/SEK3GDRZi8kTbfq.png" alt="55.png"></p><h2 id="四-准备好一些材料"><a href="#四-准备好一些材料" class="headerlink" title="(四)准备好一些材料"></a>(四)准备好一些材料</h2><h3 id="1-停用词表和专业词典"><a href="#1-停用词表和专业词典" class="headerlink" title="(1)停用词表和专业词典"></a>(1)停用词表和专业词典</h3><p>停用词表命名为TYC.txt,专业词典命名为YXZD.txt,这两个表可以自己在网上找，停用词表一般常用的是哈工大版本的，专业词典一般找医学的就行。如果不想找的话可以用我的。在百度云，链接点击右侧，提取码1998：<a href="https://pan.baidu.com/s/1sVr6t7p9I-GhOLRZgMVkhg"  target="_blank"> <font color=red > 百度网盘资料</font> </a></p><h3 id="2-文本数据"><a href="#2-文本数据" class="headerlink" title="(2)文本数据"></a>(2)文本数据</h3><p>为了体现衔接性，这里用上一期抓取的HIV数据进行情感分析，我当时抓取了1000多条，差不多够用了，如果没有数据的话可以看上一期教程自行抓取。注意文件格式是CSV格式，文件命名为“Seven.CSV”，注意文件中需要做情感分析那一列的标题改成“评论”两个字。</p><h3 id="3-注意事项"><a href="#3-注意事项" class="headerlink" title="(3)注意事项"></a>(3)注意事项</h3><p>停用词表、专业词典还有文本数据都要放到之间的项目中，我的项目在D盘Pythonworkplace文件夹里，大家如果是自己设定的目录就自己放到对应文件夹里即可。</p><h1 id="情感分析代码"><a href="#情感分析代码" class="headerlink" title="情感分析代码"></a>情感分析代码</h1><p>大家做好上述步骤后，把下边的代码复制到python中，然后右键运行，就可以在项目文件夹里看到情感分析结果啦。情感分析得分那一列，得分大于0.5为积极或支持态度，得分＜0.5为消极或反对态度。也可以划分0-0.4为消极，0.4-0.6为中立或观望态度，大于0.6为积极态度。词云图是词频的可视化，大家基本能看得懂。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#1导入需要的软件包</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> jieba.posseg <span class="keyword">as</span> posseg</span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> snownlp <span class="keyword">import</span> SnowNLP</span><br><span class="line"><span class="comment">#2加载自定义词典，以便jieba分词能分出来，自定义词典为你整理的你要的词</span></span><br><span class="line">jieba.load_userdict(<span class="string">&quot;YXZD.txt&quot;</span>)</span><br><span class="line"><span class="comment">#3加载停用词，用于去掉不需要无意义的一些词</span></span><br><span class="line">stop_word=[]</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;TYC.txt&quot;</span>,<span class="string">&quot;r&quot;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> stop:</span><br><span class="line">    words=stop.readlines()</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        stop_word.append(word.strip())</span><br><span class="line"></span><br><span class="line"><span class="comment">#4停用词去重</span></span><br><span class="line">stop_word=<span class="built_in">set</span>(stop_word)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">texts,is_comment=<span class="literal">False</span></span>):</span><br><span class="line">    word_count=[]</span><br><span class="line">    <span class="keyword">for</span> content <span class="keyword">in</span> tqdm(texts):</span><br><span class="line">        content=re.sub(<span class="string">&quot;\d+&quot;</span>,<span class="string">&quot;&quot;</span>,content)</span><br><span class="line">        <span class="keyword">if</span> is_comment:</span><br><span class="line">            content=re.findall(<span class="string">&quot;:(.+)&quot;</span>,content.strip())</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(content)&gt;<span class="number">0</span>:</span><br><span class="line">                content=content[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                content=<span class="string">&quot;&quot;</span></span><br><span class="line">        words=<span class="built_in">list</span>(posseg.cut(content))</span><br><span class="line">        <span class="keyword">if</span> is_comment:</span><br><span class="line">            pos=[<span class="string">&quot;ng&quot;</span>,<span class="string">&quot;n&quot;</span>,<span class="string">&quot;nz&quot;</span>,<span class="string">&quot;ns&quot;</span>,<span class="string">&quot;nt&quot;</span>,<span class="string">&quot;v&quot;</span>,<span class="string">&quot;vd&quot;</span>,<span class="string">&quot;a&quot;</span>,<span class="string">&quot;an&quot;</span>,<span class="string">&quot;ad&quot;</span>]</span><br><span class="line">            words=[w.word <span class="keyword">for</span> word <span class="keyword">in</span> words <span class="keyword">if</span> w.flag <span class="keyword">in</span> pos]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            words=[w.word <span class="keyword">for</span> w <span class="keyword">in</span> words]</span><br><span class="line">        words=[w <span class="keyword">for</span> w <span class="keyword">in</span> words <span class="keyword">if</span> w <span class="keyword">not</span> <span class="keyword">in</span> stop_word]</span><br><span class="line">        words = [word <span class="keyword">for</span> word <span class="keyword">in</span> words <span class="keyword">if</span> <span class="built_in">len</span>(word) &gt; <span class="number">1</span>]</span><br><span class="line">        word_count.extend(words)</span><br><span class="line">    <span class="keyword">return</span> Counter(word_count)</span><br><span class="line"><span class="comment">#5 绘制词云图</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_wordcloud</span>(<span class="params">word_count,name</span>):</span><br><span class="line">    <span class="comment">#画词云图</span></span><br><span class="line">    my_wordcloud=WordCloud(scale=<span class="number">4</span>,</span><br><span class="line">                           background_color=<span class="string">&quot;white&quot;</span>,</span><br><span class="line">                           font_path=<span class="string">&quot;simhei.ttf&quot;</span>,</span><br><span class="line">                           max_words=<span class="number">100</span>,</span><br><span class="line">                           max_font_size=<span class="number">50</span>,</span><br><span class="line">                           random_state=<span class="number">30</span>,</span><br><span class="line">                           ).generate_from_frequencies(word_count)</span><br><span class="line">    plt.figure(dpi=<span class="number">500</span>)</span><br><span class="line">    plt.imshow(my_wordcloud)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">    <span class="comment">#plt.show()</span></span><br><span class="line">    plt.savefig(<span class="string">&quot;&#123;&#125;.png&quot;</span>.<span class="built_in">format</span>(name),dpi=<span class="number">500</span>,bbox_inches=<span class="string">&quot;tight&quot;</span>)</span><br><span class="line"><span class="comment">#6 情感分析</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">comment_strip</span>(<span class="params">text</span>):</span><br><span class="line">    text = re.findall(<span class="string">&quot;(.+)&quot;</span>, text.strip())</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;&quot;</span>.join(text)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_score</span>(<span class="params">content</span>):</span><br><span class="line">    s = SnowNLP(content)</span><br><span class="line">    <span class="keyword">return</span> s.sentiments</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__== <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    df=pd.read_csv(<span class="string">&quot;seven.csv&quot;</span>,usecols=[<span class="string">&quot;评论&quot;</span>])</span><br><span class="line">    <span class="comment"># 词云图</span></span><br><span class="line">    seven = df[<span class="string">&quot;评论&quot;</span>]</span><br><span class="line">    seven = seven.drop_duplicates()</span><br><span class="line">    seven = seven.dropna()</span><br><span class="line">    seven_wordcount = process(seven)</span><br><span class="line"></span><br><span class="line">    draw_wordcloud(seven_wordcount, <span class="string">&quot;Seven的词云&quot;</span>)</span><br><span class="line">    <span class="comment"># 情感分析</span></span><br><span class="line">    comment = df[<span class="string">&quot;评论&quot;</span>]</span><br><span class="line">    comment = comment.drop_duplicates()</span><br><span class="line">    comment = comment.dropna()</span><br><span class="line">    df[<span class="string">&quot;处理后&quot;</span>] = comment.apply(comment_strip)</span><br><span class="line">    df.drop(df[(df[<span class="string">&quot;处理后&quot;</span>] == <span class="string">&quot;&quot;</span>) | (df[<span class="string">&quot;处理后&quot;</span>].isnull())].index.tolist(), inplace=<span class="literal">True</span>)</span><br><span class="line">    df[<span class="string">&quot;情感打分&quot;</span>] = df[<span class="string">&quot;处理后&quot;</span>].apply(get_score)</span><br><span class="line">    df.to_csv(<span class="string">&quot;情感分析11.csv&quot;</span>, encoding=<span class="string">&quot;gb18030&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>本次主要提到了情感分析的具体操作步骤，实际上代码不怎么难，这次教大家的是最基本的一个版本，事实上情感分析可以分析的情感并不止积极中立和消极。还有很多种形式，例如担心，害怕，开心，冷漠等等。这个涉及到高级一点的情感分析，代码也相对难一些。另外，大家其实做出来会发现，有的情感似乎不太对，或者不符合常理，这里有两个原因，一个是，这次用的是在线社区的提问做的情感分析，实际上，用微博或者抖音评论做出来会更加真实一些，因为评论的色彩更强烈。另外一个是，情感分析属于机器学习，机器学习的前提是有一个前期的训练过程。我们直接调用的这个软件包可能并不符合我们医学或者心理学中的一些情感色彩。最好的做法是先自己手工标注前100例或者更多的情感，再通过语料训练，对模型进行纠正，使模型更加准确，这个也涉及到更高级一些的情感分析，大家刚学习，可以先熟悉流程，等大家熟练后，再教给大家这些高级一些的情感分析，会更加准确。这一期大家的代码可能会有一些报错（如果没按照操作来的话），大家可以先试一试，有错误分享在留言板，谢谢，下一期教大家基于LDA主题模型提取主题。</p>]]></content>
      
      
      <categories>
          
          <category> 研究方法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LDA主题模型 </tag>
            
            <tag> 护理前沿方法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LDA主题模型第一步：数据采集</title>
      <link href="/posts/20194.html"/>
      <url>/posts/20194.html</url>
      
        <content type="html"><![CDATA[<h1 id="软件介绍"><a href="#软件介绍" class="headerlink" title="软件介绍"></a>软件介绍</h1><p>数据采集其实就是通过爬取网页中有用的一些信息的过程，也就是网络爬虫，常用的软件主要是python，R语言也可以，但是对初学者来说，尤其是非计算机专业的同学来说，会有一些困难，那有没有现成的傻瓜式工具呢，这就要提到我么今天所讲的工具：<font color=red > 八爪鱼采集器</font>。这个工具是把爬虫技术封装到软件中了，用起来相对方便一些，基本上学了就能会。但是其中还有一些注意事项，今天给大家介绍一下，话不多说，开始上手。</p><h1 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a>具体步骤</h1><h3 id="1-下载八爪鱼采集器"><a href="#1-下载八爪鱼采集器" class="headerlink" title="(1)下载八爪鱼采集器"></a>(1)下载八爪鱼采集器</h3><table><tr><td bgcolor=DarkSeaGreen>下载地址可以百度搜索一下，或者直接<a href="https://www.bazhuayu.com/download/windows"  target="_blank"> <font color=red > 点击此处</font> </a>就可以进入下载页面了。这个是Windows版本的，mac版本链接底部也能看到，下载对应版本即可。下载后自行注册一个账号，然后就可以开工啦，不用开会员，学生的话，免费版暂时够用了。</td></tr></table> <br><h3 id="2-打开有问必答网"><a href="#2-打开有问必答网" class="headerlink" title="(2)打开有问必答网"></a>(2)打开有问必答网</h3><table><tr><td bgcolor=DarkSeaGreen>我们今天教程的举例主要使用的是<a href="https://www.120ask.com/"  target="_blank"> <font color=red > 有问必答网</font> </a>，大家可以百度或者直接点击红色字体进入。文本挖掘的主要信息是：HIV患者的健康信息需求。因此请大家打开HIV相应的版块，如下图。</td></tr></table> <br><p><img src="https://s2.loli.net/2023/04/24/VrmUvpPJO7d8ENc.png" alt="11.png"></p><table><tr><td bgcolor=DarkSeaGreen>进入之后大家可以看到许多患者的提问，这个就是我们需要抓取的内容。大家把这个网页的网址复制下载，然后打开八爪鱼软件。</td></tr></table> <br><p><img src="https://s2.loli.net/2023/04/24/wfq7pMCtIj3Q6oG.png" alt="22.png"></p><h3 id="3-新建采集"><a href="#3-新建采集" class="headerlink" title="(3)新建采集"></a>(3)新建采集</h3><table><tr><td bgcolor=DarkSeaGreen>大家点击<font color=red > 新建任务 </font>，任务组命名为有问必答网。</td></tr></table> <br><p><img src="https://s2.loli.net/2023/04/24/zDGgx4ojYFLbcsP.png" alt="2.png"></p><table><tr><td bgcolor=DarkSeaGreen>将链接复制到网址一栏，然后点击<font color=red > 保存设置 </font>，会跳转到新界面。</td></tr></table> <br><p><img src="https://s2.loli.net/2023/04/24/OyHGk538qQ7lTdU.png" alt="3.png"></p><table><tr><td bgcolor=DarkSeaGreen>之后点击<font color=red > 自动识别网页 </font>，然后就不用管了，等待网页自动识别完成。</td></tr></table> <br><p><img src="https://s2.loli.net/2023/04/24/PHL8xDCknlNwbXi.png" alt="33.png"></p><table><tr><td bgcolor=DarkSeaGreen> 然后点击<font color=red > 生成采集设置 </font>。下一步很关键，点击<font color=red > 设置加载更多按钮 </font>，然后页面下拉知道看到如图下方的“下一页”按钮，点击之后，右上角的操作提示中也会出现“下一页”。然后还可以设置加载的页数，设置为200就是说抓取前200页的数据。当然这个根据自己要求设置，可以抓取前300页<font color=red > 不过大家刚开始学习的话，我建议大家只采集前50页就行，先熟悉流程后再考虑采集更多页面，因为采集页面太多，时间也会很长 </font>。之后点击“确定”。然后点击右上角保存。这样下次可以直接用这个模板进行采集，就不用设置啦。 </td></tr></table> <br><p><img src="https://s2.loli.net/2023/04/24/ZC8SUjW1aL9cB6z.png" alt="55.png"></p><h3 id="4-开始采集"><a href="#4-开始采集" class="headerlink" title="(4)开始采集"></a>(4)开始采集</h3><p>大家上一步设置好了以后，可以点击右上方进行采集。选择<font color=red > 本地采集→普通模式 </font>即可开始采集啦。然后点击右上角显示网页可以看到具体的采集过程。大家如果初次尝试的话，可以采集一些数据之后就点击停止，先熟悉流程<br><img src="https://s2.loli.net/2023/04/24/2KgG9lJkCbmjMod.png" alt="77.png"></p><h3 id="5-采集结束"><a href="#5-采集结束" class="headerlink" title="(5)采集结束"></a>(5)采集结束</h3><p>软件会根据前期设置的采集页数进行采集，采集结束后会提示采集完成，之后可以将采集的数据导出成CSV格式（我比较喜欢这种格式，用起来很方便）。<br><img src="https://s2.loli.net/2023/04/24/5pIHkqnPWXBarNQ.png" alt="88.png"><br>大家可以将数据导出到自己设置的位置。打开文件，就可以看到采集的数据啦，如下图所示：标题栏就是我们需要的信息。事实上我们可以采集到更多的信息，比如提问者的年龄、省份、性别等等，这些数据在二级页面里边，但是我们这一次主要是先熟悉流程，采集更多信息设置也会更复杂一些，为了不增加大家负担，这里先不过多介绍，后期出一个进阶版的采集攻略。<br><img src="https://s2.loli.net/2023/04/24/qKRzMLonF6537Sl.png" alt="99.png"></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>到这里，我们的采集任务就算结束啦，其实操作步骤不难，核心内容为“新建采集”部分，大家先按照我说的要求去做，其他内容先不要设置，否则可能会出错。<font color=red > 需要注意的是：数据采集是一个漫长的过程，这里演示的只是采集一级网页数据，如果多级网页采集时间会更长，有时候会需要采集4-5小时，因此建议初学者不要一次采集过多内容。实际上这个可以通过使用云服务器24h在线采集，由于操作比较麻烦，等后期大家熟练了再教给你们。 </font>好了，到这里简单的数据采集工作就算正式完成啦。我上一期讲过，情感分析应该先于LDA主题模型进行，下一期教大家<font color=red > 如何使用LDA主题模型做情感分析 </font>。情感分析很好玩的，但是可能对评论更有意思一些，对提问效果可能不是特别好，先教大家具体步骤。</p>]]></content>
      
      
      <categories>
          
          <category> 研究方法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LDA主题模型 </tag>
            
            <tag> 护理前沿方法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于LDA主题模型的文本挖掘技术在护理中的应用</title>
      <link href="/posts/15836.html"/>
      <url>/posts/15836.html</url>
      
        <content type="html"><![CDATA[<h1 id="LDA主题模型简介"><a href="#LDA主题模型简介" class="headerlink" title="LDA主题模型简介"></a>LDA主题模型简介</h1><p>在机器学习领域，LDA是两个常用模型的简称：Linear Discriminant Analysis和LatentDirichletAllocation。本文的LDA仅指代LatentDirichletAllocation.即潜在狄利克雷分布。作为基于贝叶斯学习的话题模型，是潜在语义分析模型和概率潜在语义分析模型的扩展，在文本数据挖掘、图像处理、生物信息处理等领域被广泛使用。LDA认为一篇文章是有多个主题的，而每个主题又对应着不同的词。一篇文章的构造过程，首先是以一定的概率选择某个主题，然后再在这个主题下以一定的概率选出某一个词，这样就生成了这篇文章的第一个词。不断重复这个过程，就生成了整篇文章。当然这里假定词与词之间是没顺序的。”LDA的使用是上述文档生成的逆过程，它将根据一篇得到的文章，去寻找出这篇文章的主题，以及这些主题对应的词。</p><p>上边一大串复杂的概念解释可能有些绕，通俗的解释是通过对一篇文章中词语词义的提炼，最终凝练形成几个主要的主题，即这篇文章主要讲了哪几个方面的内容，就像我现在写的这篇文章，如果进行分析的话没可能提炼出来就是，LDA的简介，在护理中的应用，实例分析等几个主题。听着和质性研究中的主题提取有一些像。但是两者还是有着本质的区别。质性研究中主题提取过于主观，要求研究者要有较高相关领域的知识。而LDA是一种无监督的自动化分析主题模型，并且具有更大是数据分析量。例如质性研究，对30例访谈资料分析已经是很大的工作量了，但是LDA可以针对几万或几十万条的文本数据进行主题分析，这样得出的结果会更加精准。这只是LDA的优势之一，另外，LDA对主题的确定更加科学，他基于困惑度和一致性进行主题确定，而不是依靠研究者主观判断。</p><p>这么一听像是质性研究主题分析的升级版，实际上LDA的作用不止于此，包括护理研究热点的识别，也可以基于LDA实现，尽管现在citespace也是护理研究热点分析的主流软件之一，但是基于LDA的主题分析，相比于citespace的传统聚类方式，会更加精准。</p><h1 id="LDA主题模型在护理中的应用"><a href="#LDA主题模型在护理中的应用" class="headerlink" title="LDA主题模型在护理中的应用"></a>LDA主题模型在护理中的应用</h1><h3 id="一-在线健康信息需求分析"><a href="#一-在线健康信息需求分析" class="headerlink" title="(一)在线健康信息需求分析"></a>(一)在线健康信息需求分析</h3><p>近年来，随着网络和社交媒体的普及，越来越多人热衷于在网络上在线问诊，以及在论坛中提问，包括疾病知识询问，以及患病体验的分享。那么，基于网络爬虫将这些知识寻求信息爬取下来，通过LDA进行分析，是否可以了解这一类患者的主要需求在哪些方面呢？尽管通过质性研究也可以获取，但是因为质性研究有了“观察者”这个角色的存在，使得很多时候获得的信息是被引导出来的，或是被刻意削弱的（尽管引导是不对的，但临床实际中很多人会这样做）。与质性研究中患者的被动回答不用，在线健康信息寻求平台抓取的信息是患者主动提问的，这实际上更加反映了患者的真实需求，并且这些在线数据常常达到了几万条或几百万条，这是质性研究无法比拟的。一些患者常常还会在网络上分析一些自己的患病体验，或是家人患病后自己的真实体验，通过对这些大数据做LDA，得出的结果会更加令人信服。因此，从这个方面来看，可以基于LDA挖掘在线平台中患者的健康信息需求，以更加真实的了解这类患者的需求和体验。博主曾经基于百度贴吧中“造口吧”的主题进行抓取，分析了造口患者的患病体验和健康信息需求，发现造口患者更多关注自身的渗漏，以及粪水性皮炎等并发症。当然这还是我2021年分析的了，数据不知道被我放哪里了。不提了</p><h3 id="二-相关人群的关注点和态度"><a href="#二-相关人群的关注点和态度" class="headerlink" title="(二)相关人群的关注点和态度"></a>(二)相关人群的关注点和态度</h3><p>这也是可以关注的一个点，所谓关注点，也就是一个一个的主题，这和上边的在线健康信息需求其实有一些像，所以主要还是在态度上，所谓态度，即对待某件事情的情感，可能是积极的，消极的，也可能是中立的。例如山东大学一位学者研究了公众对网约护士的态度。他的主要做法是通过抓取微博中与网约护士相关的话题以及每个话题下的前几百条评论（具体多少我忘记了），通过情感分析来判断大众对网约护士上门的情感态度。发现大众对网约护士持弱积极态度，之后采用LDA主题模型分析了大家主要关注点在人身安全，医疗事故责任认定等方面。但是该作者其实做的还不够好。因为他既然分析了态度，就应该根据态度进行分类后进行LDA主题挖掘。例如：持积极态度的人主要关注点在哪些方面，持消极态度的人关注点在哪些方面。这样做会更有意义，也更加体现态度在其中的作用。因为世界镇痛日是每年10月17日，每年这时候无痛分娩都会登陆热搜成为主流话题。博主之前也曾在当天抓取了大概1.7万条主要评论，通过情感分析确定了大家对于无痛分娩的态度，以及大家的关注点。也是去年10月份的事情了，识别主题的图就不放了，放一张总的词云图吧。我当时是做着玩的，没有深入分析，实际上，应该分析男性和女性对无痛分娩的态度有什么不同，或者他们的关注点有哪些差异。<br><img src="https://s2.loli.net/2023/04/22/IZrvQOqDANVFxjc.png" alt="wutongfenmian.png"></p><h3 id="三-护理研究热点的分析"><a href="#三-护理研究热点的分析" class="headerlink" title="(三)护理研究热点的分析"></a>(三)护理研究热点的分析</h3><p>这个地方不过多介绍了，大家应该都知道基于citespace的文献计量学分析，现在都被做烂了，但是LDA主题模型的优势是主题聚类更加真实，更加可靠。具体我就不多讲了，我没做过，可以去看看北京中医药大学段红梅老师的几篇文章。</p><h1 id="实现LDA主题模型和情感分析的主要步骤"><a href="#实现LDA主题模型和情感分析的主要步骤" class="headerlink" title="实现LDA主题模型和情感分析的主要步骤"></a>实现LDA主题模型和情感分析的主要步骤</h1><h3 id="一-数据采集"><a href="#一-数据采集" class="headerlink" title="(一)数据采集"></a>(一)数据采集</h3><p>这个好理解，既然要分析，就要获取数据，可以获取数据的平台：微信，知乎，39健康网，好大夫在线网等等，这些数据都可以抓取，工具呢？可以基于R语言或Python实现，但这两个对初学者来说有点难，大家可以利用现成的爬虫工具抓取，例如：八爪鱼。<span style="color:red;">等我最近更新一期八爪鱼抓取评论的视频或博客<span/></p><h3 id="二-数据清洗"><a href="#二-数据清洗" class="headerlink" title="(二)数据清洗"></a>(二)数据清洗</h3><p>主要包括空缺值的填补、噪音数据的去除，重复记录的删除，不同数据源数据的集成等。。这也好理解，你抓取的数据里边包含了很多乱七八糟的内容，看下图,里边又有表情，又有标点符号，这些都不是我们需要的，我们需要的只是文字，其他的，比如表情，还有类似于（！，’）这些都是不要的，还有用户名，都要删掉，所以这个就叫数据清洗，一条两条手动改就可以了，几十万条，当然需要软件来实现，这个不难，我后期出个文章专门教大家。<br><img src="https://s2.loli.net/2023/04/22/CUbXsNmv1YDlq87.png" alt="yuliao.png"></p><h3 id="三-分词和去除停用词处理"><a href="#三-分词和去除停用词处理" class="headerlink" title="(三)分词和去除停用词处理"></a>(三)分词和去除停用词处理</h3><p>所谓分词，很好理解，就是将一句话分成词语的最小单位，这和质性研究中还有点像呢。例如一句话“Seven是个特别喜欢钓鱼的人”，对这句话分词之后可以得到以下结果。</p><figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;Seven&quot;</span><span class="punctuation">,</span><span class="string">&quot;是&quot;</span><span class="punctuation">,</span><span class="string">&quot;个&quot;</span><span class="punctuation">,</span><span class="string">&quot;特别&quot;</span><span class="punctuation">,</span><span class="string">&quot;喜欢&quot;</span><span class="punctuation">,</span><span class="string">&quot;钓鱼&quot;</span><span class="punctuation">,</span><span class="string">&quot;的&quot;</span><span class="punctuation">,</span><span class="string">&quot;人&quot;</span></span><br></pre></td></tr></table></figure><p>这样一段话分成了8个词，但是我们发现，实际上这句话里最核心的几个词包括”Seven“，”喜欢“，”钓鱼“。而其他几个词基本上都是语气词和形容词，这些词有的时候不是我们需要的，因此可以将这些词设置成停用词，从一句话中删除，仅保留核心内容。当然有的一些标点符合也是在这个地方删除的。<br>需要注意的是：在分词时，有的时候分词会出现一些错误，例如“这真是人类之光啊”。在这句话中“人类之光”应该算作一个词，而不是“人类”，“之”，“光”这样3个词，如何保证这样的成语或专有名词不被分词切割呢。这就要用在用户词典中纳入人类之光作为一个词。具体的后边的操作中会教给大家。</p><h3 id="四-文本特征提取"><a href="#四-文本特征提取" class="headerlink" title="(四)文本特征提取"></a>(四)文本特征提取</h3><p>通过将抓取的几十万条评论进行分词后，形成了一些关键词，因此，这一步主要是统计这些关键词的特征，例如词频，也就是在这个大的主题中被提到最多的词。看我上边放的无痛分娩的词云图，可以看到“无痛”，“医生”，“麻醉师”是被提及最多的词。将这些词频通过可视化，就形成了词云图。事实上从此频来看，护理被提及的内容较少，因此我们可以思考护士，或者助产士在无痛分娩中扮演了哪些角色？如何提高护理在无痛分娩中的作用？等等。当然词频统计只是一个方面。还包括一些优化，比如词语的合并。例如卒中，脑出血，脑梗死在很多时候都可以合并为脑卒中一个词。通过对词语的合并可以使后期得到的主题更真实可靠。</p><h3 id="五-LDA主题模型的训练"><a href="#五-LDA主题模型的训练" class="headerlink" title="(五)LDA主题模型的训练"></a>(五)LDA主题模型的训练</h3><p>在进行文本特征提取后，就可以基于python或R语言进行主题模型训练了，这一步主要是为了确定最佳主题模型数，其实类似于bootstrap重复抽样。LDA训练中主要关注的指标包括困惑度，当然还有其他的，但是没有困惑度用的多一些。一般在训练时会形成一条曲线，或者说开口向上的抛物线，最低点对应的主题数即为最佳主题模型数，当然有时候会发现曲线是一直上升的，这涉及到其他一些知识，我后期细讲。</p><h3 id="六-主题聚类及结果解读"><a href="#六-主题聚类及结果解读" class="headerlink" title="(六)主题聚类及结果解读"></a>(六)主题聚类及结果解读</h3><p>这一步主要是根据确定的最佳主题数进行聚类，然后根据每个类别关键词特征进行类别命名，最后就是结果解读了<br><a href="https://shangbin.vip/LDA/LDA.html"  target="_blank"> 点击这里看这篇文章 </a><br>这个是最终可视化的LDA主题模型，这是我好久之前做的，按理说应该是分3类的，但是这个当时为了测试分了好多类，找了很久才找到这个图，先用着，大家知道一下大概是什么就行了，后期我再做一个精准一些的。</p><h1 id="LDA主题模型应用中存在的一些问题"><a href="#LDA主题模型应用中存在的一些问题" class="headerlink" title="LDA主题模型应用中存在的一些问题"></a>LDA主题模型应用中存在的一些问题</h1><p>实际上LDA主题模型在护理领域有很大的应用前景，不只是我说的这些。当然，这里边还有一些问题需要大家注意。在进行数据采集的时候，尤其是微博采集时，不要仅使用单一关键词或仅在一个话题下搜索，这会导致你的结果过于一致，最终确定主题个数时出现困惑度一直上升的现象。其次，LDA主题模型在分词过程中需要不断调整优化，才能保证最终结果准确，不是一蹴而就的。然后就是，我建议大家用这个模型挖掘在线社区的健康需求，尽量别用这个做文献热点分析，虽然有优势，但我觉得文章不好发，健康信息需求更好一些。至于LDA的其他用法，等我后期发现了再更新给大家。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>今天主要介绍了护理近期比较热门的LDA主题模型的一些内容，包括我的一些想法。现在着手开始做还不晚。我检索了一下，<span style="color:red;">目前基于LDA主题模型的在线社区HIV患者健康信息需求挖掘还没有人做过，HIV确诊后终生服药，作为慢性病患者，又面临疾病的恐惧，对这类患者的健康需求挖掘有一定意义，可以尝试做一下。</span>我之前爬取了一些数据，但是我不准备做，最近比较忙，有想做的可以考虑哦。今天主要讲了LDA，情感分析其实是独立于LDA的，但是常常和LDA同时出现在一篇文章里，后期直接把教程给大家，这个比较简单。巧妇难为无米之炊，获取数据是进行LDA的第一步，下一期先教大家如何用八爪鱼软件在网络上获取我们需要的数据，今天就到这里。有问题或者不了解的可以评论区留言，谢谢！</p>]]></content>
      
      
      <categories>
          
          <category> 研究热点 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LDA主题模型 </tag>
            
            <tag> 护理研究热点 </tag>
            
            <tag> 护理前沿方法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的第一篇博客</title>
      <link href="/posts/63786.html"/>
      <url>/posts/63786.html</url>
      
        <content type="html"><![CDATA[<h1 id="个人简介"><a href="#个人简介" class="headerlink" title="个人简介"></a>个人简介</h1><p><span style="color:red;">hello！各位小伙伴，Seven搭建的第一个博客网站就此开始营业啦！</span><br>欢迎大家的访问。简单做一下做一下自我介绍：<br>    Seven，男，1998年11月生，护理专业研究生在读。<br>    研究方向为：老年护理，心理问题的潜变量建模及心理测量学应用。<br>      兴趣爱好：钓鱼、游泳、计算机略有研究。<br>          特长：护理研究的统计分析，熟练掌握SPSS和R语言，对Mplus、Amos较熟练。<br>                对Python略有了解，能看懂代码并进行分析，但还需学习。</p><h1 id="搭建本博客的目的"><a href="#搭建本博客的目的" class="headerlink" title="搭建本博客的目的"></a>搭建本博客的目的</h1><p>搭建本博客的目的主要是进行一些护理科研和方法学的分享，众所周知，自2011年成为一级学科以来，护理学进入了快速发展阶段，特别是近年来研究生教育的普及，许多临床工作者开始进入护理研究生队列，在这个过程从发现，特别是非全日制研究的，面临一些问题，例如，统计学薄弱，选题困难，仅能发现临床现象，但不能将其转化为研究问题等等。因此，博主打算构建一个研究团队，也算是科普团队，为大家分享一些护理选题技巧，目前的研究热点，以及统计学答疑。有愿意加入团队可以留言联系我哦。<br>有人问，既然科普的话用微信公众号不就好了？还简单方便。这就要说我的第二个目的了，我个人对计算机十分爱好，搭建的目的主要还是对网页开发感兴趣，当然，这个网站建的很水，也很简单，跟真正的前端开发天壤之别，我的打算是后期慢慢的再给网站加一些内容，慢慢优化吧。总之就当是娱乐了，所以后期你们可能会看到网站时不时关闭了，那大概是我在测试新东西，但是我尽量保证不关闭吧。或者提前公告。</p><h1 id="打算的一些栏目"><a href="#打算的一些栏目" class="headerlink" title="打算的一些栏目"></a>打算的一些栏目</h1><h2 id="一-R语言入门"><a href="#一-R语言入门" class="headerlink" title="(一)R语言入门"></a>(一)R语言入门</h2><p>目前很多前沿统计分析都要用到R语言，但是大家在学习过程中常常遇到一些报错，束手无策，也有一些同学对R语言很感兴趣，但不知道从什么地方开始学起，很好，这个栏目可以帮助你入门R语言。从此R统计分析不再是问题。</p><h2 id="二-护理科研选题"><a href="#二-护理科研选题" class="headerlink" title="(二) 护理科研选题"></a>(二) 护理科研选题</h2><p>这个栏目给大家分享一些读文献的技巧，以及如何从文献中发现问题。如何在将临床现象转化为研究问题。</p><h2 id="三-护理研究热点"><a href="#三-护理研究热点" class="headerlink" title="(三)护理研究热点"></a>(三)护理研究热点</h2><p>该栏目主要分享一些现阶段护理研究的热门方向，PS：绝对是干货，不是虚头八脑的，但是我最近不怎么看文献了，可能这个栏目更新的慢一些，这个没得办法哈哈哈。当然也欢迎大家投稿。</p><h2 id="四-期刊论文打假"><a href="#四-期刊论文打假" class="headerlink" title="(四)期刊论文打假"></a>(四)期刊论文打假</h2><p>随着护理科研的发展，论文造假越来越严重，早就想开这个栏目了，比R语言入门都想开，这个地方必须经常更新，最近看到好几篇造假了，还是在核心期刊上，真的很想抨击，等我整理整理，最近就开始打假，大家看到有疑问的文章也可以留言，我去看看有没有造假。</p><h1 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h1><p>1.本人水平有限，科普过程中难免有错误，欢迎大家留言，绝不删评论，虚心学习。<br>2.因为博客刚刚搭建起来，不要问为什么除了首页、博文还有留言板开放，其他的去哪了？都说了，刚刚学会搭建，给个机会让我慢慢优化，都会做起来的。<br>3.大家有一些什么好的建议都可以在留言板留言，我看到后觉得可以的都会采纳，比如说：一些想让博主开的栏目、Mplus? Amos?等等，但是有的我是真不会啊，都是现学的，或者对网站布局有什么建议，也可以提出来，比如网站背景？一些想听的音乐？and others</p><p>代码测试：</p><figure class="highlight r"><table><tr><td class="code"><pre><span class="line">print<span class="punctuation">(</span><span class="string">&quot;This is my first Blog&quot;</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure><p>图片测试：<br><img src="https://s2.loli.net/2023/04/21/EMWgapVuBc9oRSx.jpg" alt="微信图片_20230421203218.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> Seven </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Seven </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
